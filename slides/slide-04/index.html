<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Slide 4 · Understanding LLMs</title>
    <link rel="stylesheet" href="style.css" />
  </head>
  <body data-prev="../slide-03/index.html" data-next="../slide-05/index.html">
    <main class="slide">
      <header>
        <p class="badge">Slide 4 · Technology Focus</p>
        <h1>Understanding the Technology</h1>
        <p class="lede">
          Large Language Models (LLMs) translate text prompts into visuals by
          learning patterns from immense datasets.
        </p>
      </header>

      <img src="image.png" style="width: 100%; border-radius: var(--radius);">

      <section class="content">
        <div class="accordion">
          <details class="point">
            <summary>
              <span class="label">What are LLMs?</span>
              <span class="snippet"
                >Sophisticated pattern recognition systems trained on vast human-created datasets.</span
              >
            </summary>
            <div class="detail-content">
              <p class="detail-text">
                Large Language Models (LLMs) are advanced artificial intelligence systems designed to recognize and learn intricate patterns from immense datasets of human-created text and imagery. Their functionality involves predicting the most probable next token or pixel based on these learned patterns, operating on statistical principles derived from the data they were trained on, rather than genuine understanding or consciousness.
              </p>
            </div>
          </details>

          <details class="point">
            <summary>
              <span class="label">Human-made training data</span>
              <span class="snippet"
                >Models reflect and remix the knowledge documented by humanity.</span
              >
            </summary>
            <div class="detail-content">
              <p class="detail-text">
                The capabilities of AI models are inherently limited by the scope and diversity of their human-curated training datasets. If a particular culture, artistic style, or historical narrative is underrepresented or absent from these datasets, the model cannot generate or surface it. LLMs function as sophisticated remixing engines of existing human knowledge; they cannot independently conjure concepts or creations that humanity has not yet documented or conceived.
              </p>
            </div>
          </details>

          <details class="point">
            <summary>
              <span class="label">How they work in art</span>
              <span class="snippet"
                >Textual prompts are transformed into latent visual instructions.</span
              >
            </summary>
            <div class="detail-content">
              <p class="detail-text">
                In the context of visual art generation, an LLM interprets a given text prompt, associating it with a vast array of learned visual cues and patterns. This interpretation then guides a generative model, such as a diffusion or transformer decoder, to synthesize pixels and construct an image. This process often involves hundreds of iterative steps to refine the visual output, translating abstract linguistic concepts into concrete visual representations.
              </p>
            </div>
          </details>

          <details class="point">
            <summary>
              <span class="label">Examples in visual arts</span>
              <span class="snippet"
                >Both open-source and commercial systems offer diverse creative applications.</span
              >
            </summary>
            <div class="detail-content">
              <ul class="sublist">
                <li>
                  <strong>Text-to-Image Generation:</strong> Prominent examples include DALL·E 3, Midjourney, and Stable Diffusion, which enable users to create images from textual descriptions.
                </li>
                <li>
                  <strong>Image Editing and Manipulation:</strong> Tools such as Adobe Firefly and Photoshop Generative Fill leverage AI to assist with advanced image editing, content generation, and stylistic transformations.
                </li>
              </ul>
            </div>
          </details>
        </div>
      </section>

    </main>

    <button class="nav-arrow nav-prev" type="button" aria-label="Previous slide">
      <span>&larr;</span>
    </button>
    <button class="nav-arrow nav-next" type="button" aria-label="Next slide">
      <span>&rarr;</span>
    </button>

    <script src="../shared.js"></script>
  </body>
</html>

